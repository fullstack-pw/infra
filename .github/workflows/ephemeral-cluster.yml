name: Ephemeral Cluster Management

on:
  repository_dispatch:
    types: [create_ephemeral_cluster, delete_ephemeral_cluster]

jobs:
  create-cluster:
    if: github.event.action == 'create_ephemeral_cluster'
    runs-on: self-hosted
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Check IP pool capacity
        id: check-capacity
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CAPACITY=$(./clusters/scripts/ip_pool_manager.sh check-capacity)
          echo "capacity=$CAPACITY"
          if [ "$CAPACITY" -eq 0 ]; then
            echo "::error::IP pool exhausted. All 10 ephemeral cluster slots are in use. Please close old PRs or wait for auto-cleanup."
            exit 1
          fi

      - name: Allocate IP from pool
        id: allocate
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CLUSTER_NAME="pr-${{ github.event.client_payload.repository }}-${{ github.event.client_payload.pr_number }}"
          IP=$(./clusters/scripts/ip_pool_manager.sh allocate "$CLUSTER_NAME")
          echo "ip=$IP" >> $GITHUB_OUTPUT
          echo "cluster_name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "Allocated IP: $IP for cluster: $CLUSTER_NAME"

      - name: Render Cluster API manifest
        run: |
          export CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"
          export CLUSTER_IP="${{ steps.allocate.outputs.ip }}"
          export PR_NUMBER="${{ github.event.client_payload.pr_number }}"
          export REPOSITORY="${{ github.event.client_payload.repository }}"
          envsubst < ephemeral-clusters/cluster-api/k3s-cluster.yaml.tpl > /tmp/cluster.yaml
          cat /tmp/cluster.yaml

      - name: Create cluster via Cluster API
        run: |
          kubectl apply -f /tmp/cluster.yaml --context tools

      - name: Copy proxmox-credentials secret
        run: |
          CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"
          kubectl --context tools get secret proxmox-credentials -n k3s-test -o json | \
            jq 'del(.metadata.creationTimestamp, .metadata.resourceVersion, .metadata.uid, .metadata.ownerReferences, .metadata.finalizers) | .metadata.namespace = "'$CLUSTER_NAME'"' | \
            kubectl --context tools apply -f - || echo "Warning: Could not copy proxmox-credentials"

      - name: Wait for cluster available
        run: |
          CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"
          echo "Waiting for cluster $CLUSTER_NAME to be available..."
          kubectl wait --for=condition=Available \
            cluster/$CLUSTER_NAME \
            -n $CLUSTER_NAME \
            --timeout=5m --context tools

      - name: Extract kubeconfig
        id: kubeconfig
        run: |
          CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"
          kubectl get secret ${CLUSTER_NAME}-kubeconfig \
            -n $CLUSTER_NAME \
            -o jsonpath='{.data.value}' --context tools | base64 -d > /tmp/kubeconfig
          echo "kubeconfig_path=/tmp/kubeconfig" >> $GITHUB_OUTPUT

      - name: Store kubeconfig in Vault
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"
          vault kv put kv/ephemeral-clusters/${CLUSTER_NAME}/kubeconfig \
            value=@/tmp/kubeconfig

      - name: Create Cloudflare API token secret
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CF_TOKEN=$(vault kv get -field=api-token kv/cloudflare)
          kubectl create namespace external-dns \
            --kubeconfig /tmp/kubeconfig \
            --dry-run=client -o yaml | kubectl apply --kubeconfig /tmp/kubeconfig -f -
          kubectl create secret generic cloudflare-api-token \
            --from-literal=api-token="$CF_TOKEN" \
            -n external-dns \
            --kubeconfig /tmp/kubeconfig \
            --dry-run=client -o yaml | kubectl apply --kubeconfig /tmp/kubeconfig -f -

      - name: Install Phase 1 - Operators
        run: |
          kubectl apply -k ephemeral-clusters/phase1-operators/ --kubeconfig /tmp/kubeconfig

      - name: Install CloudNativePG via Helm
        run: |
          helm repo add cloudnative-pg https://cloudnative-pg.github.io/charts || true
          helm repo update cloudnative-pg
          helm install cnpg cloudnative-pg/cloudnative-pg \
            --namespace cnpg-system \
            --create-namespace \
            --kubeconfig /tmp/kubeconfig \
            --wait --timeout=3m

      - name: Wait for operators ready
        run: |
          echo "Waiting for cert-manager..."
          kubectl wait --for=condition=Available deployment/cert-manager \
            -n cert-manager --timeout=3m --kubeconfig /tmp/kubeconfig

          echo "Waiting for external-dns..."
          kubectl wait --for=condition=Available deployment/external-dns-cloudflare \
            -n external-dns --timeout=3m --kubeconfig /tmp/kubeconfig

          echo "Waiting for external-secrets..."
          kubectl wait --for=condition=Available deployment/external-secrets \
            -n external-secrets --timeout=3m --kubeconfig /tmp/kubeconfig

          echo "Waiting for CloudNativePG..."
          kubectl wait --for=condition=Available deployment/cnpg-cloudnative-pg \
            -n cnpg-system --timeout=3m --kubeconfig /tmp/kubeconfig

      - name: Wait for CRDs established
        run: |
          kubectl wait --for condition=established --timeout=3m --kubeconfig /tmp/kubeconfig \
            crd/certificates.cert-manager.io \
            crd/clusterissuers.cert-manager.io \
            crd/dnsendpoints.externaldns.k8s.io \
            crd/secretstores.external-secrets.io \
            crd/externalsecrets.external-secrets.io \
            crd/clusters.postgresql.cnpg.io \
            crd/backups.postgresql.cnpg.io

      - name: Install Phase 2 - Resources
        run: |
          export DNS_NAME="pr-${{ github.event.client_payload.pr_number }}-${{ github.event.client_payload.repository }}.ephemeral.fullstack.pw"
          export CLUSTER_IP="${{ steps.allocate.outputs.ip }}"
          export CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"

          # Apply ClusterIssuer (static)
          kubectl apply -f ephemeral-clusters/phase2-resources/clusterissuer.yaml --kubeconfig /tmp/kubeconfig

          # Apply templated resources
          for f in ephemeral-clusters/phase2-resources/*.tpl; do
            envsubst < "$f"
          done | kubectl apply --kubeconfig /tmp/kubeconfig -f -

      - name: Wait for DNS propagation
        run: |
          DNS_NAME="pr-${{ github.event.client_payload.pr_number }}-${{ github.event.client_payload.repository }}.ephemeral.fullstack.pw"
          CLUSTER_IP="${{ steps.allocate.outputs.ip }}"

          echo "Waiting for DNS propagation of $DNS_NAME to $CLUSTER_IP..."
          timeout 300 bash -c "
            until dig +short $DNS_NAME | grep -q '$CLUSTER_IP'; do
              echo 'Waiting for DNS propagation...'
              sleep 5
            done
          " || echo "DNS propagation timeout - may take additional time"

      - name: Post cluster info comment
        if: success()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PAT_TOKEN }}
          script: |
            const clusterName = '${{ steps.allocate.outputs.cluster_name }}';
            const clusterIP = '${{ steps.allocate.outputs.ip }}';
            const dnsName = `pr-${{ github.event.client_payload.pr_number }}-${{ github.event.client_payload.repository }}.ephemeral.fullstack.pw`;

            const body = `## ðŸš€ Ephemeral Cluster Ready

**Cluster Name:** \`${clusterName}\`
**Cluster IP:** \`${clusterIP}\`
**DNS:** \`${dnsName}\`
**Status:** âœ… Ready for deployment

The ephemeral cluster is now available for testing. Your application will be deployed shortly.

---
*This cluster will auto-cleanup 1 hour after PR close or after 3 days maximum lifetime.*`;

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: '${{ github.event.client_payload.repository }}',
              issue_number: ${{ github.event.client_payload.pr_number }},
              body: body
            });

      - name: Cleanup on failure
        if: failure()
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CLUSTER_NAME="${{ steps.allocate.outputs.cluster_name }}"

          # Delete cluster if it was created
          kubectl delete cluster $CLUSTER_NAME -n $CLUSTER_NAME --context tools --ignore-not-found=true

          # Release IP
          ./clusters/scripts/ip_pool_manager.sh release "$CLUSTER_NAME" || true

          # Remove kubeconfig from Vault
          vault kv delete kv/ephemeral-clusters/${CLUSTER_NAME}/kubeconfig || true

  delete-cluster:
    if: github.event.action == 'delete_ephemeral_cluster'
    runs-on: self-hosted
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Delete Cluster API resources
        run: |
          CLUSTER_NAME="${{ github.event.client_payload.cluster_name }}"
          echo "Deleting cluster: $CLUSTER_NAME"

          kubectl delete cluster $CLUSTER_NAME -n $CLUSTER_NAME --context tools --ignore-not-found=true

          # Wait for cluster deletion
          kubectl wait --for=delete cluster/$CLUSTER_NAME -n $CLUSTER_NAME \
            --timeout=5m --context tools || true

          # Delete namespace
          kubectl delete namespace $CLUSTER_NAME --context tools --ignore-not-found=true

      - name: Release IP from pool
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CLUSTER_NAME="${{ github.event.client_payload.cluster_name }}"
          ./clusters/scripts/ip_pool_manager.sh release "$CLUSTER_NAME"

      - name: Remove kubeconfig from Vault
        run: |
          export VAULT_ADDR=https://vault.fullstack.pw
          export VAULT_TOKEN=${{ secrets.VAULT_TOKEN }}
          CLUSTER_NAME="${{ github.event.client_payload.cluster_name }}"
          vault kv delete kv/ephemeral-clusters/${CLUSTER_NAME}/kubeconfig || true

      - name: Delete ArgoCD Application
        run: |
          CLUSTER_NAME="${{ github.event.client_payload.cluster_name }}"
          APP_NAME=$(echo "$CLUSTER_NAME" | sed 's/pr-//')
          kubectl delete application $APP_NAME -n argocd --context tools --ignore-not-found=true

      - name: Post cleanup confirmation
        if: success()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PAT_TOKEN }}
          script: |
            const clusterName = '${{ github.event.client_payload.cluster_name }}';

            const body = `## ðŸ§¹ Ephemeral Cluster Deleted

**Cluster Name:** \`${clusterName}\`
**Status:** âœ… Cleaned up

Resources released:
- âœ… VM deleted from Proxmox
- âœ… IP returned to pool
- âœ… Kubeconfig removed from Vault
- âœ… DNS records removed

---
*Ephemeral cluster resources have been fully cleaned up.*`;

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: '${{ github.event.client_payload.repository }}',
              issue_number: ${{ github.event.client_payload.pr_number }},
              body: body
            });
